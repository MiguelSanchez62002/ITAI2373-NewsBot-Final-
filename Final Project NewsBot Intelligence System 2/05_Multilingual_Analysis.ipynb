{
  "metadata": {
    "kernelspec": {
      "name": "xpython",
      "display_name": "Python 3.13 (XPython)",
      "language": "python"
    },
    "language_info": {
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "version": "3.13.1"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "f218b38f-7619-4693-81a4-ac14fee0e09a",
      "cell_type": "code",
      "source": "# üéØ Intent Classification and Query Understanding# TODO: Implement conversational AI capabilitiesclass ConversationalInterface:    \"\"\"    Advanced conversational AI for natural language interaction with NewsBot    TODO: Build sophisticated query understanding and response generation    \"\"\"        def __init__(self, newsbot_system):        self.newsbot = newsbot_system        # TODO: Initialize conversational components        # Hint: Consider:        # - Intent classification models        # - Entity extraction from queries        # - Context management        # - Response templates        # - Conversation state tracking        pass        def classify_intent(self, user_query):        \"\"\"        TODO: Classify user intent from natural language query                Common intents might include:        - \"search\" - Find articles about X        - \"summarize\" - Summarize articles about Y        - \"analyze\" - Analyze sentiment/trends for Z        - \"compare\" - Compare coverage of A vs B        - \"explain\" - Explain entity relationships        \"\"\"        pass        def extract_query_entities(self, user_query):        \"\"\"        TODO: Extract entities and parameters from user queries                Examples:        - \"Show me positive tech news from this week\"          -> entities: sentiment=positive, category=tech, timeframe=week        - \"Compare Apple and Google coverage\"          -> entities: companies=[Apple, Google], task=compare        \"\"\"        pass        def process_query(self, user_query, conversation_context=None):        \"\"\"        TODO: Process natural language query and generate response                This is the main interface between users and your NewsBot!                Should handle:        - Intent classification        - Entity extraction        - Query execution        - Response generation        - Context management        \"\"\"        pass        def generate_response(self, query_results, intent, entities):        \"\"\"        TODO: Generate helpful, natural language responses                Responses should be:        - Informative and accurate        - Appropriately detailed        - Actionable when possible        - Conversational in tone        \"\"\"        pass        def handle_follow_up(self, follow_up_query, conversation_history):        \"\"\"        TODO: Handle follow-up questions with context awareness                Examples:        - User: \"Show me tech news\"        - Bot: [shows results]        - User: \"What about from last month?\" (needs context)        \"\"\"        pass# TODO: Test your conversational interface# conversation = ConversationalInterface(newsbot_system)print(\"üí¨ Conversational interface ready for implementation!\")\n# Conversational Interface\nimport re\nfrom collections import defaultdict\nimport spacy\nfrom nltk.sentiment import SentimentIntensityAnalyzer\n\n# Load spaCy model and NLTK sentiment analyzer\nnlp = spacy.load(\"en_core_web_sm\")\nsia = SentimentIntensityAnalyzer()\n\nclass ConversationalInterface:\n    \"\"\"\n    Conversational Interface for NewsBot 2.0\n    - Uses spaCy for NER\n    - Uses NLTK SentimentIntensityAnalyzer for sentiment\n    - Handles context for follow-up queries\n    \"\"\"\n\n    def __init__(self, newsbot_system):\n        self.newsbot = newsbot_system\n        self.context = {}\n\n        # Intent keyword mapping from midterm structure\n        self.intent_keywords = {\n            \"search\": [\"find\", \"show\", \"get\", \"list\", \"look for\", \"news\", \"latest\"],\n            \"summarize\": [\"summarize\", \"summary\", \"brief\", \"short version\"],\n            \"analyze\": [\"analyze\", \"analysis\", \"trend\", \"pattern\", \"sentiment\"],\n            \"compare\": [\"compare\", \"difference\", \"vs\", \"versus\", \"contrast\"],\n            \"explain\": [\"explain\", \"relationship\", \"connection\", \"how\"]\n        }\n\n        # Predefined categories from midterm datasets\n        self.categories = [\"technology\", \"tech\", \"sports\", \"economy\", \"business\", \"politics\", \"health\"]\n\n    # Intent classification\n    def classify_intent(self, user_query: str) -> str:\n        query_lower = user_query.lower()\n        for intent, keywords in self.intent_keywords.items():\n            if any(keyword in query_lower for keyword in keywords):\n                return intent\n        return \"search\"  # default intent\n\n    # Entity extraction\n    def extract_query_entities(self, user_query: str) -> dict:\n        doc = nlp(user_query)\n        entities = defaultdict(list)\n\n        # Named Entities from spaCy\n        for ent in doc.ents:\n            entities[ent.label_].append(ent.text)\n\n        # Categories\n        for cat in self.categories:\n            if re.search(r\"\\b\" + re.escape(cat) + r\"\\b\", user_query, flags=re.I):\n                entities[\"category\"].append(cat)\n\n        # Timeframes\n        if re.search(r\"\\btoday\\b\", user_query, flags=re.I):\n            entities[\"timeframe\"].append(\"today\")\n        elif re.search(r\"\\bthis week\\b|\\blast week\\b\", user_query, flags=re.I):\n            entities[\"timeframe\"].append(\"week\")\n        elif re.search(r\"\\bthis month\\b|\\blast month\\b\", user_query, flags=re.I):\n            entities[\"timeframe\"].append(\"month\")\n\n        # Sentiment (using keywords + NLTK analysis)\n        if re.search(r\"\\bpositive\\b\", user_query, flags=re.I):\n            entities[\"sentiment\"].append(\"positive\")\n        elif re.search(r\"\\bnegative\\b\", user_query, flags=re.I):\n            entities[\"sentiment\"].append(\"negative\")\n        else:\n            score = sia.polarity_scores(user_query)[\"compound\"]\n            if score >= 0.05:\n                entities[\"sentiment\"].append(\"positive\")\n            elif score <= -0.05:\n                entities[\"sentiment\"].append(\"negative\")\n            else:\n                entities[\"sentiment\"].append(\"neutral\")\n\n        return dict(entities)\n\n    # Main query processing\n    def process_query(self, user_query: str) -> str:\n        intent = self.classify_intent(user_query)\n        entities = self.extract_query_entities(user_query)\n\n        # Save context\n        self.context[\"last_intent\"] = intent\n        self.context[\"last_entities\"] = entities\n\n        # Call NewsBot system\n        results = self.newsbot.run_query(intent, entities)\n\n        return self.generate_response(results, intent, entities)\n\n    # Handle follow-up\n    def handle_follow_up(self, follow_up_query: str) -> str:\n        new_entities = self.extract_query_entities(follow_up_query)\n\n        # Merge with previous entities\n        merged = dict(self.context.get(\"last_entities\", {}))\n        for k, v in new_entities.items():\n            if v:\n                merged[k] = v\n\n        intent = self.context.get(\"last_intent\", self.classify_intent(follow_up_query))\n        self.context[\"last_entities\"] = merged\n        self.context[\"last_intent\"] = intent\n\n        results = self.newsbot.run_query(intent, merged)\n        return self.generate_response(results, intent, merged)\n\n    # Response formatting\n    def generate_response(self, results: list, intent: str, entities: dict) -> str:\n        entity_str = \", \".join(f\"{k}: {v}\" for k, v in entities.items())\n        intent_headers = {\n            \"search\": \"üîç Search results\",\n            \"summarize\": \"üìù Summary\",\n            \"analyze\": \"üìä Analysis\",\n            \"compare\": \"‚öñÔ∏è Comparison\",\n            \"explain\": \"üß† Explanation\"\n        }\n        header = intent_headers.get(intent, \"Results\")\n        body = \"\\n\".join(f\"{i+1}. {r}\" for i, r in enumerate(results))\n        return f\"{header} ({entity_str}):\\n{body}\"\n\n\n# Example test with dummy adapter\nclass DummyNewsBot:\n    def run_query(self, intent, entities):\n        return [f\"Article about {entities} (Intent: {intent})\", \"Another related article\"]\n\n# Example usage\nif __name__ == \"__main__\":\n    bot = DummyNewsBot()\n    convo = ConversationalInterface(bot)\n\n    print(convo.process_query(\"Show me positive tech news from this week\"))\n    print(convo.handle_follow_up(\"What about last month?\"))\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "dd4dfda5-a46b-4515-ace9-a64d01f47fb6",
      "cell_type": "code",
      "source": "# üì¢ Conversational Interface for NewsBot 2.0\nimport re\nfrom collections import defaultdict\nfrom typing import Dict, Any, List\n\nclass ConversationalInterface:\n    \"\"\"\n    Section 5 implementation:\n    - Intent classification\n    - Entity extraction\n    - Context management\n    - Response generation\n    - Follow-up handling\n    \"\"\"\n\n    def __init__(self, newsbot_adapter):\n        \"\"\"\n        newsbot_adapter: an object with methods:\n          search(), summarize(), analyze(), compare(), explain()\n        \"\"\"\n        self.newsbot = newsbot_adapter\n        self.context = {}  # store last_intent, last_entities\n\n        # Intent keywords (you can expand as needed)\n        self.intent_keywords = {\n            \"search\": [\"show\", \"find\", \"news\", \"search\", \"get\", \"list\", \"give me\"],\n            \"summarize\": [\"summarize\", \"summary\", \"brief\", \"short\"],\n            \"analyze\": [\"analyze\", \"analysis\", \"sentiment\", \"trend\", \"trends\"],\n            \"compare\": [\"compare\", \"versus\", \"vs\", \"difference\", \"contrast\"],\n            \"explain\": [\"explain\", \"what is\", \"how\", \"relationship\", \"relations\"]\n        }\n\n    # Intent classification\n    def classify_intent(self, user_query: str) -> str:\n        q = user_query.lower()\n        for intent in [\"compare\", \"analyze\", \"summarize\", \"explain\", \"search\"]:\n            for kw in self.intent_keywords[intent]:\n                if kw in q:\n                    return intent\n        return \"search\"\n\n    # Entity extraction\n    def extract_query_entities(self, user_query: str) -> Dict[str, Any]:\n        # If spaCy is available in your Midterm code, use it\n        try:\n            doc = nlp(user_query)\n            entities = defaultdict(list)\n            for ent in doc.ents:\n                entities[ent.label_].append(ent.text)\n        except NameError:\n            entities = defaultdict(list)\n\n        # Categories\n        categories = [\"tech\", \"technology\", \"sports\", \"economy\", \"business\", \"politics\", \"health\"]\n        for cat in categories:\n            if re.search(r\"\\b\" + re.escape(cat) + r\"\\b\", user_query, flags=re.I):\n                entities[\"category\"].append(cat)\n\n        # Timeframe extraction\n        if re.search(r\"\\bthis month\\b|\\blast month\\b\", user_query, flags=re.I):\n            entities[\"timeframe\"].append(\"month\")\n        if re.search(r\"\\bthis week\\b|\\blast week\\b\", user_query, flags=re.I):\n            entities[\"timeframe\"].append(\"week\")\n        if re.search(r\"\\btoday\\b|\\bthis morning\\b|\\bthis afternoon\\b\", user_query, flags=re.I):\n            entities[\"timeframe\"].append(\"today\")\n\n        # Sentiment\n        if re.search(r\"\\bpositive\\b|\\bnegative\\b|\\bneutral\\b\", user_query, flags=re.I):\n            match = re.search(r\"\\b(positive|negative|neutral)\\b\", user_query, flags=re.I)\n            if match:\n                entities[\"sentiment\"].append(match.group(1).lower())\n\n        # Company names (fallback if spaCy not available)\n        if \"companies\" not in entities or not entities[\"companies\"]:\n            titles = re.findall(r\"\\b[A-Z][a-z]{2,}(?:\\s[A-Z][a-z]{2,})*\\b\", user_query)\n            filtered = [t for t in titles if t.lower() not in {\"this\", \"please\", \"what\", \"who\", \"show\"}]\n            if filtered:\n                entities[\"companies\"].extend(filtered)\n\n        # Flatten single values\n        out = {}\n        for k, v in entities.items():\n            vals = list(dict.fromkeys(v))\n            out[k.lower()] = vals if len(vals) > 1 else (vals[0] if vals else [])\n        return out\n\n    # Execute intent\n    def execute(self, intent: str, entities: Dict[str, Any]) -> List[str]:\n        if intent == \"search\":\n            return self.newsbot.search(entities)\n        elif intent == \"summarize\":\n            return self.newsbot.summarize(entities)\n        elif intent == \"analyze\":\n            return self.newsbot.analyze(entities)\n        elif intent == \"compare\":\n            return self.newsbot.compare(entities)\n        elif intent == \"explain\":\n            return self.newsbot.explain(entities)\n        else:\n            return [\"I couldn't understand the action you want.\"]\n\n    # Format response\n    def generate_response(self, results: List[str], intent: str, entities: Dict[str, Any]) -> str:\n        ent_summary = \", \".join(f\"{k}={v}\" for k, v in entities.items() if v)\n        header = {\n            \"search\": f\"üîç Search results {f'({ent_summary})' if ent_summary else ''}:\",\n            \"summarize\": f\"üìù Summary {f'({ent_summary})' if ent_summary else ''}:\",\n            \"analyze\": f\"üìä Analysis {f'({ent_summary})' if ent_summary else ''}:\",\n            \"compare\": f\"‚öñÔ∏è Comparison {f'({ent_summary})' if ent_summary else ''}:\",\n            \"explain\": f\"üß† Explanation {f'({ent_summary})' if ent_summary else ''}:\",\n        }.get(intent, \"Results:\")\n        body = \"\\n\".join(f\"{i+1}. {r}\" for i, r in enumerate(results))\n        return f\"{header}\\n{body}\"\n\n    # Process new query\n    def process_query(self, user_query: str) -> str:\n        intent = self.classify_intent(user_query)\n        entities = self.extract_query_entities(user_query)\n        self.context[\"last_intent\"] = intent\n        self.context[\"last_entities\"] = entities\n        results = self.execute(intent, entities)\n        return self.generate_response(results, intent, entities)\n\n    # Handle follow-up query\n    def handle_follow_up(self, follow_up_query: str) -> str:\n        new_entities = self.extract_query_entities(follow_up_query)\n        merged = dict(self.context.get(\"last_entities\", {}))\n        for k, v in new_entities.items():\n            if v:\n                merged[k] = v\n        intent = self.context.get(\"last_intent\", self.classify_intent(follow_up_query))\n        self.context[\"last_entities\"] = merged\n        self.context[\"last_intent\"] = intent\n        results = self.execute(intent, merged)\n        return self.generate_response(results, intent, merged)\n\n\n# Example usage with a dummy adapter for testing\nclass DummyNewsBotAdapter:\n    def search(self, entities): return [f\"Found news for {entities}\"]\n    def summarize(self, entities): return [f\"Summary for {entities}\"]\n    def analyze(self, entities): return [f\"Analysis for {entities}\"]\n    def compare(self, entities): return [f\"Comparison for {entities}\"]\n    def explain(self, entities): return [f\"Explanation for {entities}\"]\n\nif __name__ == \"__main__\":\n    adapter = DummyNewsBotAdapter()\n    ci = ConversationalInterface(adapter)\n\n    print(ci.process_query(\"Show me positive tech news from this week\"))\n    print(ci.handle_follow_up(\"What about last month?\"))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}